


### 一、背景介绍
   spark 是和hadoop 一样的分布式数据计算框架,但是hadoop是基于HDFS 文件存储的,而 spark 是基于内存的 所以速度上来说 是要比hadoop要快的.其根本在于将**数据转成表**  
   #### 主要部件
   ![image](image/spark组件.png)
   * spark core
        - RDD:弹性分布式数据集,只读的分区记录的集合，只能基于在稳定物理存储中的数据集和其他已有的RDD上执行确定性操作来创建  
        - DAG:有向无环图  
   * spark sql
        
   
   这里是python 操作所需要知道的名词
   * DataFrame: 基本的表 如果进行处理 这个可以说是基本单位
   
   #### 环境安装
   * windows 操作系统
   * python 3.7
   * pySpark 库
   * hadoop 
   
   
###  连接数据的方案
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  