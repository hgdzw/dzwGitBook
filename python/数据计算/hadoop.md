> 数据本身是无用的，除非你能从中获取到有价值的洞察。

### 一、啥是大数据，啥是hadoop？
   在科技日新月异的今天数据的存储已经不是一个硬盘能存储的，当我们对海量的数据进行存储、管理、计算的时候就用到了大数据的技术。
   其中比较有名的就是hadoop和spark，而hadoop又是什么呢，它是目前**一套主流的技术体系**，包括
   * HDFS: 分布式文件系统，用来存储数据。
   * YARN: 分布式资源调度系统，用来管理和调度节点
   * MapReduce: 分布式计算系统，用来将要计算的海量算力进行拆分到很多台机器上计算 并将结果聚合。
   
### 二、HDFS(分布式存储系统)
   我们用HDFS系统来分布式管理文件,既然是分布式肯定有很多的系统，其中的角色
   
   #### 2.1 NameNode 
   当有很多台机器的时候 就需要有一个主节点，他就是NameNode 它上面**负责管理整个HDFS集群的元数据**，比如说，文件目录树、权限的设置、副本数的设置    
   其他的副节点都是 DataNode 
   
   因为文件目录树是放在内存中，所以当每次内存修改完毕之后,都会写一条edits log文件,当这个节点重启之后可以从edits log 进行重放
   
   ##### 2.1.1 NameNode 的架构
   当只有一台namenode 如果宕机了怎么办,这个时候就需要两台来实现。 故障转移
   
   引入一个新的磁盘文件叫做 fsimage，然后呢，再引入一个JournalNodes集群，以及一个Standby NameNode（备节点）。
   
   每次写edits log 的时候都会向 JournalNodes 集群写一份，然后备用节点就从集群拉一份 这样 备用节点和主节点的数据就保持一致了。
   
   然后每隔一段时间，Standby NameNode都把自己内存里的文件目录树写一份到磁盘上的fsimage，这可不是日志，这是完整的一份元数据。这个操作就是所谓的checkpoint检查点操作。
   
   如果主节点重启，那么从备用节点传过来的 fsimage 读取到内存中，就很快。
   
   ##### 2.1.2 NameNode 是怎么顶得住每秒上千次的并发访问的
   我们知道每一次访问namenode 都会做这个操作
   1. 写本地的edits log
   2. 将edits log 向远程 JournalNodes 备份一份
   
   当并发访问的时候有一个全局的xid 来区分那个edits log 的先来后到 必须上锁，然后就会导致 加锁的时候进行本地写和网络写 这是非常耗费性能的 所以要将这两个写 放到锁外面去。
   ![image](../image/Hadoop%20NameNode%20并发写的流程.png)
   用到了 分段加锁机制 + 内存双缓冲机制
   
   
   
   #### 2.x 文件上传是怎么进行优化的？
   如果只是普通的 文件输入流在内存中 拷贝到文件输出流 传输到datanode 那性能肯定是极低的。
   
   所以要加入缓冲和异步的技术, 将输入流分段写入一个段里面,将很多个段打包成一个 包放进一个内存队列中,然后用一个线程只监听这个内存队列进行网络传输。
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   